"use strict";(globalThis.webpackChunkkris_kerr_senior_technical_writer=globalThis.webpackChunkkris_kerr_senior_technical_writer||[]).push([[6810],{4167(e,t,s){s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"neural-networks","title":"Neural Networks","description":"A deep-diving discussion on the Neural Networks algorithm","source":"@site/docs/neural-networks.md","sourceDirName":".","slug":"/neural-networks","permalink":"/kris.kerr.professional.website/docs/neural-networks","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/neural-networks.md","tags":[],"version":"current","frontMatter":{"title":"Neural Networks","description":"A deep-diving discussion on the Neural Networks algorithm","keywords":["neural","network","networks","algorithm","algorithms"]},"sidebar":"rgoneSidebar","previous":{"title":"Partial Least Squares","permalink":"/kris.kerr.professional.website/docs/partial-least-squares"},"next":{"title":"Clustering algorithms","permalink":"/kris.kerr.professional.website/docs/clustering-algorithms"}}');var n=s(4848),o=s(8453);const i={title:"Neural Networks",description:"A deep-diving discussion on the Neural Networks algorithm",keywords:["neural","network","networks","algorithm","algorithms"]},a=void 0,l={},d=[{value:"Nodes and layers",id:"nodes-and-layers",level:2}];function u(e){const t={em:"em",h2:"h2",img:"img",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.p,{children:["The ",(0,n.jsx)(t.em,{children:"Neural Networks"})," algorithm passes input features forward through a sequence of layers before turning them into outputs. In each layer, inputs are weighted in various combinations, summed, and passed on to the next layer."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"Nonlinear models slide",src:s(5058).A+"",title:"Nonlinear models slide",width:"972",height:"552"})}),"\n",(0,n.jsx)(t.p,{children:"Note that selecting the Neural Networks algorithm displays additional algorithm parameters that control and/or constrain the modeling process."}),"\n",(0,n.jsx)(t.h2,{id:"nodes-and-layers",children:"Nodes and layers"}),"\n",(0,n.jsxs)(t.p,{children:["A ",(0,n.jsx)(t.em,{children:"node"})," is a model of a single neuron in the brain (which sums up all the inputs and triggers the output if a given threshold is reached). A ",(0,n.jsx)(t.em,{children:"layer"}),' is a group of nodes at the same "level".']}),"\n",(0,n.jsx)(t.p,{children:"Per proven theory, two layers is enough to map any regression prediction task. However, theory doesn't specify how to do it (just that it can be done). The number of nodes in a layer, node functions, and weights need to be discovered through training."}),"\n",(0,n.jsxs)(t.p,{children:["A good rule of thumb is that the number of nodes in a layer should usually be proportional to the number of input features. In most cases, 2-3 layers should be sufficient for most prediction problems. The default ",(0,n.jsx)(t.strong,{children:"layer"})," and ",(0,n.jsx)(t.strong,{children:"node"}),' values should work for most situations. Note that using larger numbers of nodes and layers facilitates learning at the expense of training time and increases the risk of overtraining (that is, learning the unwanted "noise").']})]})}function c(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(u,{...e})}):u(e)}},5058(e,t,s){s.d(t,{A:()=>r});const r=s.p+"assets/images/nonlinear-models-slide-27320a8c4755b54aeff71080dd015caf.png"},8453(e,t,s){s.d(t,{R:()=>i,x:()=>a});var r=s(6540);const n={},o=r.createContext(n);function i(e){const t=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:i(e.components),r.createElement(o.Provider,{value:t},e.children)}}}]);